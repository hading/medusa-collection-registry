development:
  #'cfs' staging file config. Note that this doesn't strictly need to be a dx/cfs file system,
  #but we use that name in order to distinguish from our internal bit file stuff for now.
  cfs:
    root: /home/hading/repos/medusa-rails3/tmp/cfs-root-dev
    export_root: /home/hading/repos/medusa-rails3/tmp/cfs-export-root-dev
    export_autoclean: false
  staging:
    #an array of hashes which have the local_path (i.e. as the medusa server sees it) and the remote_path
    #what will be recorded in the external file path)
    roots:
      - local_path: /Users/hding2/repos/medusa-rails3/tmp/staging-root-1
        remote_path: /staging-root-1
      - local_path: /Users/hding2/repos/medusa-rails3/tmp/staging-root-2
        remote_path: /staging-root-2
  #This opens a few actions to basic auth so that machine clients can use them
  basic_auth: machine_user:machine_password
  #AD groups used to allow use and full administration of medusa
  medusa_users_group: Library Medusa Users
  medusa_admins_group: Library Medusa Admins
  #Configuration for the amazon backup
  amazon:
    #threshold where we start a new bag, in megabytes
    maximum_bag_size: 10240
    #directory to be used for creating and zipping bags, storing manifests
    bag_storage_root: /home/hading/medusa-rails3/tmp/amazon-development
    #AMQP queues to communicate with glacier server
    outgoing_queue: medusa_to_glacier
    incoming_queue: glacier_to_medusa
test:
  cfs:
    root: /home/hading/repos/medusa-rails3/tmp/cfs-root-test
    export_root: /home/hading/repos/medusa-rails3/tmp/cfs-export-root-test
    export_autoclean: false
  #the tests assume the following
  basic_auth: machine_user:machine_password
  medusa_users_group: Library Medusa Users
  medusa_admins_group: Library Medusa Admins
production:
  basic_auth: change_this_user:change_this_password
  medusa_users_group: Library Medusa Users
  medusa_admins_group: Library Medusa Admins
  cfs:
    root: /path/to/cfs/root
    export_root: /path/to/cfs/exports
    export_autoclean: true
